# AI-Driven Facial Emotion Detection with Music Recommendation and Mental Health Tip

## ğŸ“– Overview

Presents an intelligent wellness system that integrates **AI-powered facial emotion recognition** with **personalized music recommendation** and **mental health tips**. The goal is to enhance emotional well-being by identifying the user's mood through facial expressions and responding with therapeutic content tailored to that mood.

---

## ğŸš€ Features

- ğŸ§  **Facial Emotion Detection** using CNN and MediaPipe Face Mesh
- ğŸµ **Music Recommendation System** tailored to the user's current emotional state
- ğŸ©º **Mental Health Tips** generated based on detected mood
- ğŸ§¾ **Emotion History Tracking** for user self-awareness over time
- ğŸ”’ **User Authentication** with facial recognition login
- ğŸ“Š **Real-Time Analytics** and emotion trend visualization
- ğŸ® **GUI Interface** built with Tkinter for easy interaction

---

## ğŸ§° Tech Stack & Tools

| Technology        | Usage                              |
|------------------|-------------------------------------|
| Python           | Core programming language           |
| TensorFlow & Keras | Deep Learning model (CNN)         |
| OpenCV           | Image processing and face detection |
| MediaPipe        | Facial landmark detection (Face Mesh) |
| Tkinter          | GUI Development                     |
| Pyttsx3          | Text-to-speech for tips             |
| Pygame           | Playing music based on emotion      |

---

## ğŸ› ï¸ System Architecture

The emotion detection system uses a **multi-CNN pipeline** to analyze facial components:
- CNN-1: Eyebrow + Eye Region
- CNN-2: Eye Detection
- CNN-3: Mouth Region
- Logical operations (AND/OR) consolidate features before final expression detection via CNN-4.

MediaPipe extracts landmarks â†’ Features mapped â†’ Processed by CNN â†’ Emotion classified â†’ Output personalized recommendation (music + tip).

![Architecture Diagram Placeholder]

---

## ğŸ“‚ Folder Structure
AI-Emotion-Music-Recommendation/
â”‚
â”œâ”€â”€ dataset/ # Training datasets (FER-2013 or custom)
â”œâ”€â”€ models/ # Trained CNN models
â”œâ”€â”€ music/ # Music files categorized by emotion
â”œâ”€â”€ src/ # Core application logic
â”‚ â”œâ”€â”€ emotion_detect.py # CNN model + prediction pipeline
â”‚ â”œâ”€â”€ music_player.py # Music recommendation logic
â”‚ â”œâ”€â”€ health_tips.py # Tip generation module
â”‚ â”œâ”€â”€ gui.py # Tkinter GUI interface
â”‚ â””â”€â”€ login_auth.py # User authentication logic
â”‚
â”œâ”€â”€ logs/ # User emotion history logs
â”œâ”€â”€ requirements.txt # Required Python packages
â”œâ”€â”€ README.md # Project documentation
â””â”€â”€ main.py # Entry point of the application



---

## ğŸ“¸ Input & Output Flow

1. **User Login** â Secure authentication
2. **Image Upload** â Captures or selects face image
3. **Emotion Detection** â Model predicts (Happy, Sad, Angry, etc.)
4. **Output**:
   - ğŸµ Emotion-aligned music played
   - ğŸ§˜â€â™‚ï¸ Health tip shown via speech/text
   - ğŸ“Š Emotion trend tracked & saved

---

## ğŸ§ª Results

- **Accuracy**: ~75% emotion detection accuracy on varied datasets
- **Real-time Feedback**: Emotion â†’ Instant music + tip
- **User Satisfaction**: Interactive and personalized response boosts user engagement
- **Emotion Trends**: Graphs generated over time for emotional awareness

---

## âœ… Requirements

- Python 3.8+
- TensorFlow
- OpenCV
- Keras
- MediaPipe
- Tkinter
- Pygame
- Pyttsx3

Install all dependencies using:

```bash
pip install -r requirements.txt


â–¶ï¸ How to Run the Project
Clone the repo:

git clone https://github.com/yourusername/AI-Emotion-Music-Recommendation.git
cd AI-Emotion-Music-Recommendation
Install dependencies:
pip install -r requirements.txt
Run the main file:


python main.py
ğŸ“ˆ Future Scope
Real-time webcam-based emotion detection
Integration with wearable sensors (heart rate, etc.)
Expand dataset for multilingual emotion cues
Mobile app version using Flutter/Kivy
Enhanced privacy features and data anonymization

ğŸ”’ Ethical Considerations
Respect user privacy and ensure data is processed locally.
No image or emotion data is uploaded/stored on external servers.
Designed with transparency and user consent in mind.

